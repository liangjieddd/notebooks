[TOC]

# 目标检测回顾

## 1.选择性搜索

​		目标检测的第一步是要做**候选区域**（Region Proposal），也就是找出可能的感兴趣区域（Region Of Interest, ROI）。

​		候选区域类似于光学字符识别（OCR）领域的切分，OCR切分常用过切分方法，简单说就是**尽量切碎到小的连通域**（比如小的笔画之类），然后再根据**相邻块的一些形态学特征进行合并**。但目标检测的对象相比OCR领域千差万别，而且图形不规则，大小不一，所以一定程度上可以说候选区域是比OCR切分更难的一个问题。

### **候选区域方法**

一、滑动窗口。

​		滑动窗口本质上就是**穷举法**，利用不同的尺度和长宽比把所有可能的大大小小的块都穷举出来，然后送去识别，识别出来概率大的就留下来。很明显，这样的方法复杂度太高，产生了很多的冗余候选区域，在现实当中不可行。

二、规则块。

​		在穷举法的基础上进行了一些剪枝，只选用**固定的大小和长宽比。**这在一些特定的应用场景是很有效的，比如汉字检测，因为汉字方方正正，长宽比大多比较一致，因此用规则块做区域提名是一种比较合适的选择。但是对于普通的目标检测来说，规则块依然需要访问很多的位置，复杂度高。

三、选择性搜索。

​		从机器学习的角度来说，前面的方法召回是不错了，但是精度差强人意，所以问题的核心在于如何**有效地去除冗余候选区域**。其实冗余候选区域大多是发生了重叠，选择性搜索利用这一点，**自底向上合并相邻的重叠区域**，从而减少冗余。

​		候选区域并不只有以上所说的三种方法，实际上这块是非常灵活的，因此变种也很多，有兴趣的读者不妨参考一下文献[12]。

​		选择性搜索的具体算法细节[8]如算法1所示。总体上选择性搜索是**自底向上不断合并候选区域的迭代过程**。

~~~
输入: 一张图片
输出：候选的目标位置集合L
算法：
1: 利用过切分方法得到候选的区域集合R = {r1,r2,…,rn}
2: 初始化相似集合S = ϕ
3: foreach 邻居区域对(ri,rj) do
4: 计算相似度s(ri,rj)
5: S = S ∪ s(ri,rj)
6: while S not=ϕ do
7: 得到最大的相似度s(ri,rj)=max(S)
8: 合并对应的区域rt = ri ∪ rj
9: 移除ri对应的所有相似度：S = S\s(ri,r*)
10: 移除rj对应的所有相似度：S = S\s(r*,rj)
11: 计算rt对应的相似度集合St
12: S = S ∪ St
13: R = R ∪ rt
14: L = R中所有区域对应的边框
~~~

​		从算法不难看出，*R*中的区域都是合并后的，因此减少了不少冗余，相当于准确率提升了，但是别忘了我们还需要继续保证召回率，因此算法1中的相似度计算策略就显得非常关键了。如果简单采用一种策略很容易错误合并不相似的区域，比如只考虑轮廓时，不同颜色的区域很容易被误合并。

​		选择性搜索采用多样性策略来增加候选区域以保证召回，比如颜色空间考虑RGB、灰度、HSV及其变种等，相似度计算时既考虑颜色相似度，又考虑纹理、大小、重叠情况等。

​		总体上，选择性搜索是一种比较朴素的候选区域方法，被早期的基于深度学习的目标检测方法（包括Overfeat和R-CNN等）广泛利用，但被当前的新方法弃用了。

## 2.OverFeat

​		OverFeat是用CNN统一来做分类、定位和检测的经典之作，作者是深度学习大神之一Yann Lecun在纽约大学的团队。OverFeat也是ILSVRC 2013任务3（分类+定位）的冠军得主[10]。

OverFeat的核心思想有三点：

1. 候选区域：结合滑动窗口和规则块，即多尺度（multi-scale)的滑动窗口；
2. 分类和定位：统一用CNN来做分类和预测边框位置，模型与AlexNet类似，
   1. 其中1-5层为**特征抽取层**，即将图片转换为固定维度的特征向量
   2. 6-9层为**分类层**(分类任务专用)，
   3. 不同的任务（分类、定位、检测）公用特征抽取层（1-5层），只替换6-9层；
3. 累积：因为用了滑动窗口，同一个目标对象会有多个位置，也就是多个视角；因为用了多尺度，同一个目标对象又会有多个大小不一的块。这些不同位置和不同大小块上的分类置信度会进行累加，从而使得判定更为准确。

**OverFeat的关键步骤有四步：**

1. **利用滑动窗口进行不同尺度的候选区域，然后使用CNN模型对每个区域进行分类，得到类别和置信度。从图2中可以看出，不同缩放比例时，检测出来的目标对象数量和种类存在较大差异；**![img](http://mmbiz.qpic.cn/mmbiz_png/1MtnAxmWSwPPSORYeKnIib6QLia67I4fLricVf5m9032Y5fUm5vxv5iaG12b2RahqKqbybO8RV6luZzQLGew4rEYAw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)图2 Overfeat关键步骤一

2. **利用多尺度滑动窗口来增加检测数量，提升分类效果，如图3所示；**![img](http://mmbiz.qpic.cn/mmbiz_png/1MtnAxmWSwPPSORYeKnIib6QLia67I4fLrrwg0Oc5R5aefYaibQoPMuhVj7zYdQLVE1vvubiaIld5Pcx2WgjlOCx4Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)图3 Overfeat关键步骤二

3. **用回归模型预测每个对象的位置，从图4中来看，放大比例较大的图片，边**

   **框数量也较多；**

   ![img](http://mmbiz.qpic.cn/mmbiz_png/1MtnAxmWSwPPSORYeKnIib6QLia67I4fLr3BT7RpPJHpEuKYPnSXBia8WqVtPpABBic59Mkic8HHNnPHcE4Y5TXfqWA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)图4 Overfeat关键步骤三

4. **边框合并。**![img](http://mmbiz.qpic.cn/mmbiz_png/1MtnAxmWSwPPSORYeKnIib6QLia67I4fLr1JBSFKFUcpU0VKZHlrDvOwxMpdewZNnUbkR7HY0I5cQguTfC7Vqxng/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

   图5 Overfeat关键步骤四

   Overfeat是CNN用来做目标检测的早期工作，主要思想是采用了多尺度滑动窗口来做分类、定位和检测，虽然是多个任务但重用了模型前面几层，这种模型重用的思路也是后来R-CNN系列不断沿用和改进的经典做法。

   当然Overfeat也是有不少缺点的，至少速度和效果都有很大改进空间，后面的R-CNN系列在这两方面做了很多提升。